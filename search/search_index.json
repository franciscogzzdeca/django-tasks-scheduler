{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Django tasks Scheduler","text":"<p>  []pypi</p> <p>A database backed asynchronous tasks scheduler for django. This allows remembering scheduled tasks, their parameters, etc.</p> <p>Important</p> <p>Version 3.0.0 introduced a major design change. Instead of three separate models, there is one new <code>Task</code> model. The goal is to simplify. Make sure to follow the migration guide</p>"},{"location":"#terminology","title":"Terminology","text":""},{"location":"#scheduled-task","title":"Scheduled Task","text":"<p>Starting v3.0.0, django-tasks-scheduler is using a single <code>Task</code> model with different task types, the task types are:</p> <ul> <li><code>ONCE</code> - Run the task once at a scheduled time.</li> <li><code>REPEATABLE</code> - Run the task multiple times (limited number of times or infinite times) based on a time interval.</li> <li><code>CRON</code> - Run a task indefinitely based on a cron string schedule.</li> </ul> <p>This enables having one admin view for all scheduled tasks, and having one table in the database to maintain the task reduces the number of overall queries. An <code>Task</code> instance contains all relevant information about a task to enable the users to schedule using django-admin and track their status.</p> <p>Previously, there were three different models for ScheduledTask. These exist for legacy purposes and are scheduled to be removed.</p> <ul> <li><code>Scheduled Task</code> - Run a task once, on a specific time (can be immediate).</li> <li><code>Repeatable Task</code> - Run a task multiple times (limited number of times or infinite times) based on an interval</li> <li><code>Cron Task</code> - Run a task multiple times (limited number of times or infinite times) based on a cron string</li> </ul> <p>Scheduled tasks are scheduled when the django application starts, and after a scheduled task is executed.</p>"},{"location":"#queue","title":"Queue","text":"<p>A queue of messages between processes (main django-app process and worker usually). This is implemented in <code>rq</code> package.</p> <ul> <li>A queue contains multiple registries for scheduled tasks, finished jobs, failed jobs, etc.</li> </ul>"},{"location":"#worker","title":"Worker","text":"<p>A process listening to one or more queues for jobs to be executed, and executing jobs queued to be executed.</p>"},{"location":"#scheduler","title":"Scheduler","text":"<p>A process listening to one or more queues for jobs to be scheduled for execution, and schedule them to be executed by a worker.</p> <p>This is a subprocess of worker.</p>"},{"location":"#queued-job-execution","title":"Queued Job Execution","text":"<p>Once a worker listening to the queue becomes available, the job will be executed</p>"},{"location":"#scheduled-job-execution","title":"Scheduled Job Execution","text":"<p>A scheduler checking the queue periodically will check whether the time the job should be executed has come, and if so, it will queue it.</p> <ul> <li>A job is considered scheduled if it is queued to be executed, or scheduled to be executed.</li> <li>If there is no scheduler, the job will not be queued to run.</li> </ul>"},{"location":"#scheduler-sequence-diagram","title":"Scheduler sequence diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    box Worker\n        participant scheduler as Scheduler Process\n    end\n    box DB\n        participant db as Database\n\n    end\n    box Redis queue\n        participant queue as Queue\n        participant schedule as Queue scheduled tasks\n    end\n    loop Scheduler process - loop forever\n        note over scheduler, schedule: Database interaction\n        scheduler -&gt;&gt; db: Check for enabled tasks that should be scheduled\n        critical There are tasks to be scheduled\n            scheduler -&gt;&gt; schedule: Create a job for task that should be scheduled\n        end\n        note over scheduler, schedule: Redis queues interaction\n        scheduler -&gt;&gt; schedule: check whether there are scheduled tasks that should be executed\n        critical there are jobs that are scheduled to be executed\n            scheduler -&gt;&gt; schedule: remove jobs to be scheduled\n            scheduler -&gt;&gt; queue: enqueue jobs to be executed\n        end\n        scheduler -&gt;&gt; scheduler: sleep interval (See SCHEDULER_INTERVAL)\n    end</code></pre>"},{"location":"#worker-sequence-diagram","title":"Worker sequence diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    box Worker\n        participant worker as Worker Process\n    end\n    box Redis queue\n        participant queue as Queue\n        participant finished as Queue finished jobs\n        participant failed as Queue failed jobs\n    end\n    loop Worker process - loop forever\n        worker -&gt;&gt;+ queue: get the first job to be executed\n        queue --&gt;&gt;- worker: A job to be executed or nothing\n        critical There is a job to be executed\n            worker -&gt;&gt; queue: Remove job from queue\n            worker -&gt;&gt; worker: Execute job\n            critical Job ended successfully\n                worker -&gt;&gt; finished: Write job result\n            option Job ended unsuccessfully\n                worker -&gt;&gt; failed: Write job result\n            end\n        option No job to be executed\n            worker -&gt;&gt; worker: sleep\n        end\n    end</code></pre>"},{"location":"#reporting-issues-or-features-requests","title":"Reporting issues or Features requests","text":"<p>Please report issues via GitHub Issues .</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>A lot of django-admin views and their tests were adopted from django-rq.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v300","title":"v3.0.0 \ud83c\udf08","text":""},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>Renamed <code>REDIS_CLIENT_KWARGS</code> configuration to <code>CLIENT_KWARGS</code>.</li> </ul>"},{"location":"changelog/#features","title":"\ud83d\ude80 Features","text":"<ul> <li>Created a new <code>Task</code> model representing all kind of scheduled tasks.<ul> <li>In future versions, <code>CronTask</code>, <code>ScheduledTask</code> and <code>RepeatableTask</code> will be removed.</li> <li><code>Task</code> model has a <code>task_type</code> field to differentiate between the types of tasks.</li> <li>Old tasks in the database will be migrated to the new <code>Task</code> model automatically.</li> </ul> </li> </ul>"},{"location":"changelog/#v211","title":"v2.1.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Support for valkey sentinel configuration @amirreza8002 (#191)</li> </ul>"},{"location":"changelog/#v210","title":"v2.1.0 \ud83c\udf08","text":""},{"location":"changelog/#features_1","title":"\ud83d\ude80 Features","text":"<ul> <li>Support for custom job-class for every worker, using <code>--job-class</code> option in <code>rqworker</code> command. @gabriels1234 (#160)</li> <li>Support for integrating with sentry, using <code>--sentry-dsn</code>, <code>--sentry-debug</code>, and <code>--sentry-ca-certs</code> options in   <code>rqworker</code> command.</li> <li>Support for using ValKey as broker instead of redis.</li> </ul>"},{"location":"changelog/#maintenance","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Refactor settings module.</li> </ul>"},{"location":"changelog/#v200","title":"v2.0.0 \ud83c\udf08","text":""},{"location":"changelog/#breaking-changes_1","title":"Breaking Changes","text":"<ul> <li>Remove support for django 3.* and 4.*. Only support django 5.0 and above.</li> </ul>"},{"location":"changelog/#v134","title":"v1.3.4 \ud83c\udf08","text":""},{"location":"changelog/#maintenance_1","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies to latest versions</li> </ul>"},{"location":"changelog/#v133","title":"v1.3.3 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_1","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix issue of django generating a new migration when settings.SCHEDULER_QUEUES is changed #119</li> </ul>"},{"location":"changelog/#v132","title":"v1.3.2 \ud83c\udf08","text":"<ul> <li>Fix issue with job_details template on python3.12 @cyber237 #87</li> </ul>"},{"location":"changelog/#v131","title":"v1.3.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_2","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix workers' page when there are no queues #83</li> </ul>"},{"location":"changelog/#maintenance_2","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Removes psycopg2 dependency from pyproject.toml @mbi (#78)</li> </ul>"},{"location":"changelog/#v130","title":"v1.3.0 \ud83c\udf08","text":""},{"location":"changelog/#features_2","title":"\ud83d\ude80 Features","text":"<ul> <li>Add to CronTask and RepeatableTask counters for successful/failed runs.</li> </ul>"},{"location":"changelog/#maintenance_3","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Support for django 5.0</li> <li>Update homepage url @dirkmueller (#65)</li> </ul>"},{"location":"changelog/#v124","title":"v1.2.4 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_3","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix for non-existent task @gabriels1234 (#62)</li> </ul>"},{"location":"changelog/#maintenance_4","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Use rq <code>fetch_many</code></li> </ul>"},{"location":"changelog/#v123","title":"v1.2.3 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_4","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix When a job fails it becomes unscheduled #45</li> </ul>"},{"location":"changelog/#v121","title":"v1.2.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_5","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix infinite loop on callback calling is_scheduled() #37.</li> </ul>"},{"location":"changelog/#v120","title":"v1.2.0 \ud83c\udf08","text":""},{"location":"changelog/#features_3","title":"\ud83d\ude80 Features","text":"<ul> <li>Rename <code>*Job</code> models to <code>*Task</code> to differentiate.</li> </ul>"},{"location":"changelog/#v110","title":"v1.1.0 \ud83c\udf08","text":""},{"location":"changelog/#features_4","title":"\ud83d\ude80 Features","text":"<ul> <li>Enable using stats view using api token</li> <li>Reverted, active jobs are not marked as scheduled as there is currently no new job instance for them.</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"\ud83d\udc1b Bug Fixes","text":""},{"location":"changelog/#32-running-jobs-should-be-marked-as-scheduled-jobs-rstalbow-33","title":"32 Running jobs should be marked as scheduled jobs. @rstalbow (#33)","text":""},{"location":"changelog/#v102","title":"v1.0.2 \ud83c\udf08","text":""},{"location":"changelog/#maintenance_5","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies</li> </ul>"},{"location":"changelog/#bug-fixes_7","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Add missing migration and check for missing migrations</li> </ul>"},{"location":"changelog/#v101","title":"v1.0.1 \ud83c\udf08","text":"<ul> <li>Update dependencies</li> <li>Remove redundant log calls</li> </ul>"},{"location":"changelog/#v100","title":"v1.0.0 \ud83c\udf08","text":"<ul> <li>Migrated from django-rq-scheduler</li> </ul>"},{"location":"commands/","title":"Management commands","text":""},{"location":"commands/#rqworker","title":"rqworker","text":"<p>Create a new worker with a scheduler for specific queues by order of priority. If no queues are specified, will run on default queue only.</p> <p>All queues must have the same redis settings on <code>SCHEDULER_QUEUES</code>.</p> <pre><code>usage: manage.py rqworker [-h] [--pid PIDFILE] [--burst] [--name NAME] [--worker-ttl WORKER_TTL] [--max-jobs MAX_JOBS]\n                          [--fork-job-execution FORK_JOB_EXECUTION] [--job-class JOB_CLASS] [--sentry-dsn SENTRY_DSN] [--sentry-debug]\n                          [--sentry-ca-certs SENTRY_CA_CERTS] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH]\n                          [--traceback] [--no-color] [--force-color] [--skip-checks]\n                          [queues ...]\n\npositional arguments:\n  queues                The queues to work on, separated by space, all queues should be using the same redis\n\noptions:\n  -h, --help            show this help message and exit\n  --pid PIDFILE         file to write the worker`s pid into\n  --burst               Run worker in burst mode\n  --name NAME           Name of the worker\n  --worker-ttl WORKER_TTL\n                        Default worker timeout to be used\n  --max-jobs MAX_JOBS   Maximum number of jobs to execute before terminating worker\n  --fork-job-execution FORK_JOB_EXECUTION\n                        Fork job execution to another process\n  --job-class JOB_CLASS\n                        Jobs class to use\n  --sentry-dsn SENTRY_DSN\n                        Sentry DSN to use\n  --sentry-debug        Enable Sentry debug mode\n  --sentry-ca-certs SENTRY_CA_CERTS\n                        Path to CA certs file\n  --version             Show program's version number and exit.\n  -v {0,1,2,3}, --verbosity {0,1,2,3}\n                        Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output\n  --settings SETTINGS   The Python path to a settings module, e.g. \"myproject.settings.main\". If this isn't provided, the\n                        DJANGO_SETTINGS_MODULE environment variable will be used.\n  --pythonpath PYTHONPATH\n                        A directory to add to the Python path, e.g. \"/home/djangoprojects/myproject\".\n  --traceback           Raise on CommandError exceptions.\n  --no-color            Don't colorize the command output.\n  --force-color         Force colorization of the command output.\n  --skip-checks         Skip system checks.\n</code></pre>"},{"location":"commands/#export","title":"export","text":"<p>Export all scheduled tasks from django db to json/yaml format.</p> <pre><code>python manage.py export -o {yaml,json}\n</code></pre> <p>Result should be (for json):</p> <pre><code>[\n  {\n    \"model\": \"ScheduledJob\",\n    \"name\": \"Scheduled Task 1\",\n    \"callable\": \"scheduler.tests.test_job\",\n    \"callable_args\": [\n      {\n        \"arg_type\": \"datetime\",\n        \"val\": \"2022-02-01\"\n      }\n    ],\n    \"callable_kwargs\": [],\n    \"enabled\": true,\n    \"queue\": \"default\",\n    \"at_front\": false,\n    \"timeout\": null,\n    \"result_ttl\": null,\n    \"scheduled_time\": \"2023-02-21T14:06:06\"\n  },\n  ...\n]\n</code></pre>"},{"location":"commands/#import","title":"import","text":"<p>A json/yaml that was exported using the <code>export</code> command can be imported to django.</p> <ul> <li>Specify the source file using <code>--filename</code> or take it from the standard input (default).</li> <li>Reset all scheduled tasks in the database before importing using <code>-r</code>/<code>--reset</code>.</li> <li>Update existing jobs for names that are found using <code>-u</code>/<code>--update</code>.</li> </ul> <pre><code>python manage.py import -f {yaml,json} --filename {SOURCE-FILE}\n</code></pre>"},{"location":"commands/#run_job","title":"run_job","text":"<p>Run a method in a queue immediately.</p> <pre><code>python manage.py run_job {callable} {callable args ...}\n</code></pre>"},{"location":"commands/#delete-failed-jobs","title":"delete failed jobs","text":"<p>Run this to empty failed jobs registry from a queue.</p> <pre><code>python manage.py delete_failed_jobs \n</code></pre>"},{"location":"configuration/","title":"Configure your django-tasks-scheduler","text":""},{"location":"configuration/#settingspy","title":"settings.py","text":"<p>All default settings for scheduler can be in one dictionary in <code>settings.py</code>:</p> <pre><code>SCHEDULER_CONFIG = {\n    'EXECUTIONS_IN_PAGE': 20,\n    'DEFAULT_RESULT_TTL': 500,\n    'DEFAULT_TIMEOUT': 300,  # 5 minutes\n    'SCHEDULER_INTERVAL': 10,  # 10 seconds\n    'BROKER': 'redis',\n}\nSCHEDULER_QUEUES = {\n    'default': {\n        'HOST': 'localhost',\n        'PORT': 6379,\n        'DB': 0,\n        'USERNAME': 'some-user',\n        'PASSWORD': 'some-password',\n        'DEFAULT_TIMEOUT': 360,\n        'CLIENT_KWARGS': {  # Eventual additional Redis connection arguments\n            'ssl_cert_reqs': None,\n        },\n        'TOKEN_VALIDATION_METHOD': None,  # Method to validate auth-header\n    },\n    'high': {\n        'URL': os.getenv('REDISTOGO_URL', 'redis://localhost:6379/0'),  # If you're on Heroku\n        'DEFAULT_TIMEOUT': 500,\n    },\n    'low': {\n        'HOST': 'localhost',\n        'PORT': 6379,\n        'DB': 0,\n    }\n}\n</code></pre>"},{"location":"configuration/#scheduler_config-executions_in_page","title":"SCHEDULER_CONFIG: <code>EXECUTIONS_IN_PAGE</code>","text":"<p>Number of job executions to show in a page in a ScheduledJob admin view.</p> <p>Default: <code>20</code>.</p>"},{"location":"configuration/#scheduler_config-default_result_ttl","title":"SCHEDULER_CONFIG: <code>DEFAULT_RESULT_TTL</code>","text":"<p>Default time to live for job execution result.</p> <p>Default: <code>600</code> (10 minutes).</p>"},{"location":"configuration/#scheduler_config-default_timeout","title":"SCHEDULER_CONFIG: <code>DEFAULT_TIMEOUT</code>","text":"<p>Default timeout for job when it is not mentioned in queue. Default: <code>300</code> (5 minutes).</p>"},{"location":"configuration/#scheduler_config-scheduler_interval","title":"SCHEDULER_CONFIG: <code>SCHEDULER_INTERVAL</code>","text":"<p>Default scheduler interval, a scheduler is a subprocess of a worker and will check which job executions are pending.</p> <p>Default: <code>10</code> (10 seconds).</p>"},{"location":"configuration/#scheduler_config-token_validation_method","title":"SCHEDULER_CONFIG: <code>TOKEN_VALIDATION_METHOD</code>","text":"<p>Method to validate request <code>Authorization</code> header with. Enables checking stats using API token.</p> <p>Default: no tokens allowed.</p>"},{"location":"configuration/#scheduler_config-broker","title":"SCHEDULER_CONFIG: <code>BROKER</code>","text":"<p>Broker driver to use for the scheduler. Can be <code>redis</code> or <code>valkey</code> or <code>fakeredis</code>.</p> <p>Default: <code>redis</code>.</p>"},{"location":"configuration/#scheduler_queues","title":"<code>SCHEDULER_QUEUES</code>","text":"<p>You can configure the queues to work with. That way you can have different workers listening to different queues.</p> <p>Different queues can use different redis servers/connections.</p>"},{"location":"drt-model/","title":"Worker related flows","text":"<p>Running <code>python manage.py startworker --name 'X' --queues high default low</code></p>"},{"location":"drt-model/#register-new-worker-for-queues","title":"Register new worker for queues","text":"<pre><code>sequenceDiagram\n    autonumber\n\n        participant worker as WorkerProcess\n\n        participant qlist as QueueHash&lt;br/&gt;name -&gt; key \n        participant wlist as WorkerList\n        participant wkey as WorkerKey\n        participant queue as QueueKey\n        participant job as JobHash\n\n\n    note over worker,qlist: Checking sanity\n\n    break when a queue-name in the args is not in queue-list\n        worker -&gt;&gt;+ qlist: Query queue names\n        qlist --&gt;&gt;- worker: All queue names\n        worker -&gt;&gt; worker: check that queue names exists in the system\n    end\n\n    note over worker,wkey: register\n    worker -&gt;&gt; wkey: Create workerKey with all info (new id, queues, status)\n    worker -&gt;&gt; wlist: Add new worker to list, last heartbeat set to now()</code></pre>"},{"location":"drt-model/#work-execute-jobs-on-queues","title":"Work (execute jobs on queues)","text":"<pre><code>sequenceDiagram\n    autonumber\n\n        participant worker as WorkerProcess\n\n        participant qlist as QueueHash&lt;br/&gt;name -&gt; key \n        participant wlist as WorkerList\n        participant wkey as WorkerKey\n        participant queue as QueueKey\n        participant job as JobHash\n\n    loop Until death\n        worker -&gt;&gt; wlist: Update last heartbeat\n        note over worker,job: Find next job\n\n        loop over queueKeys until job to run is found or all queues are empty\n            worker -&gt;&gt;+ queue: get next job id and remove it or None (zrange+zpop)\n            queue --&gt;&gt;- worker: job id / nothing\n        end\n\n        note over worker,job: Execute job or sleep\n        critical [job is found]\n            worker -&gt;&gt; wkey: Update worker status to busy\n            worker -&gt;&gt;+ job: query job data\n            job --&gt;&gt;- worker: job data\n\n            worker -&gt;&gt; job: update job status to running\n            worker -&gt;&gt; worker: execute job\n            worker -&gt;&gt; job: update job status to done/failed\n            worker -&gt;&gt; wkey: Update worker status to idle\n        option No job pending\n            worker -&gt;&gt; worker: sleep    \n        end  \n    end</code></pre>"},{"location":"drt-model/#scheduler-flows","title":"Scheduler flows","text":""},{"location":"installation/","title":"Installation","text":"<ol> <li> <p>Use pip to install:    <pre><code>pip install django-tasks-scheduler\n</code></pre></p> </li> <li> <p>In <code>settings.py</code>, add <code>scheduler</code> to  <code>INSTALLED_APPS</code>:    <pre><code>INSTALLED_APPS = [\n    # ...    \n    'scheduler',\n    # ...\n]\n</code></pre></p> </li> <li> <p>Configure your queues.    Add at least one Redis Queue to your <code>settings.py</code>:    <pre><code>import os\nSCHEDULER_QUEUES = {\n  'default': {\n      'HOST': 'localhost',\n      'PORT': 6379,\n     'DB': 0,\n      'USERNAME': 'some-user',\n      'PASSWORD': 'some-password',\n      'DEFAULT_TIMEOUT': 360,\n      'CLIENT_KWARGS': {    # Eventual additional Redis connection arguments\n          'ssl_cert_reqs': None,\n      },\n  },\n  'with-sentinel': {\n      'SENTINELS': [('localhost', 26736), ('localhost', 26737)],\n      'MASTER_NAME': 'redismaster',\n      'DB': 0,\n      # Redis username/password\n      'USERNAME': 'redis-user',\n      'PASSWORD': 'secret',\n      'SOCKET_TIMEOUT': 0.3,\n      'CONNECTION_KWARGS': {  # Eventual additional Redis connection arguments\n          'ssl': True\n      },\n      'SENTINEL_KWARGS': {    # Eventual Sentinel connection arguments\n          # If Sentinel also has auth, username/password can be passed here\n          'username': 'sentinel-user',\n          'password': 'secret',\n      },\n  },\n  'high': {\n      'URL': os.getenv('REDISTOGO_URL', 'redis://localhost:6379/0'), # If you're on Heroku\n      'DEFAULT_TIMEOUT': 500,\n  },\n  'low': {\n      'HOST': 'localhost',\n      'PORT': 6379,\n      'DB': 0,\n  }\n}\n</code></pre></p> </li> <li> <p>Optional: Configure default values for queuing jobs from code:    <pre><code>SCHEDULER_CONFIG = {\n 'EXECUTIONS_IN_PAGE': 20,\n 'DEFAULT_RESULT_TTL': 500,\n 'DEFAULT_TIMEOUT': 300,  # 5 minutes\n 'SCHEDULER_INTERVAL': 10,  # 10 seconds\n 'BROKER': 'redis', # \n}\n</code></pre></p> </li> <li> <p>Add <code>scheduler.urls</code> to your django application <code>urls.py</code>:    <pre><code>from django.urls import path, include\n\nurlpatterns = [\n    # ...\n    path('scheduler/', include('scheduler.urls')),\n]\n</code></pre></p> </li> <li> <p>Run migrations to generate django models    <pre><code>python manage.py migrate\n</code></pre></p> </li> </ol>"},{"location":"migrate_to_v3/","title":"Migration from v2 to v3","text":"<p>Version 3.0.0 introduced a major design change. Instead of three separate models, there is one new <code>Task</code> model. The goal is to have one centralized admin view for all your scheduled tasks, regardless of the scheduling type.</p> <p>You need to migrate the scheduled tasks using the old models (<code>ScheduledTask</code>, <code>RepeatableTask</code>, <code>CronTask</code>) to the new model. It can be done using the export/import commands provided.</p> <p>After upgrading to django-tasks-scheduler v3.0.0, you will notice you are not able to create new scheduled tasks in the old models, that is intentional. In the next version of django-tasks-scheduler (v3.1), the old models will be deleted, so make sure you migrate your old models.</p> <p>Note</p> <p>While we tested different scenarios heavily and left the code for old tasks, we could not account for all different use cases, therefore, please open an issue if you encounter any.</p> <p>There are two ways to migrate your existing scheduled tasks:</p>"},{"location":"migrate_to_v3/#using-the-admin-views-of-the-old-models","title":"Using the admin views of the old models","text":"<p>If you go to the admin view of the old models, you will notice there is a new action in the actions drop down menu for migrating the selected tasks. Use it, and you will also have a link to the new task to compare the migration result.</p> <p>Note once you migrate using this method, the old task will be disabled automatically.</p>"},{"location":"migrate_to_v3/#exportimport-management-commands","title":"Export/Import management commands","text":"<p>Run in your project directory:</p> <pre><code>python manage.py export &gt; scheduled_tasks.json\npython manage.py import --filename scheduled_tasks.json\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#enqueue-jobs-from-code","title":"Enqueue jobs from code","text":"<pre><code>from scheduler import job\n\n\n@job\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function in \"default\" queue\n</code></pre> <p>Specifying the queue where the job should be queued:</p> <pre><code>@job('high')\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function in \"high\" queue\n</code></pre> <p>You can pass in any arguments that RQ's job decorator accepts:</p> <pre><code>from scheduler import job\n\n\n@job('default', timeout=3600)\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function with a timeout of 3600 seconds.\n</code></pre> <p>You can set in <code>settings.py</code> a default value for <code>DEFAULT_RESULT_TTL</code> and <code>DEFAULT_TIMEOUT</code>.</p> <pre><code># settings.py\nSCHEDULER_CONFIG = {\n    'DEFAULT_RESULT_TTL': 360,\n    'DEFAULT_TIMEOUT': 60,\n}\n</code></pre>"},{"location":"usage/#scheduling-a-job-through-django-admin","title":"Scheduling a job Through django-admin","text":"<ul> <li>Sign in to the Django Admin site (e.g., http://localhost:8000/admin/) and locate the <code>Tasks Scheduler</code> section.</li> <li>Click on the Add link for the type of job you want to add (<code>Scheduled Task</code> - run once, <code>Repeatable Task</code> - run   multiple times, <code>Cron Task</code> - Run based on cron schedule).</li> <li>Enter a unique name for the job in the Name field.</li> <li>In the Callable field, enter a Python dot notation path to the method that defines the job. For the example   above, that would be <code>myapp.jobs.count</code></li> <li>Choose your Queue.   The queues listed are defined in your app <code>settings.py</code> under <code>SCHEDULER_QUEUES</code>.</li> <li>Enter the time in UTC the job is to be executed in the Scheduled time field.</li> </ul>"},{"location":"usage/#optional-fields","title":"Optional fields:","text":"<ul> <li>Select whether the job should take priority over existing queued jobs when it is queued (jobs waiting to be executed)   by using at front.</li> <li>Timeout specifies the maximum time in seconds the job is allowed to run. blank value means it can run forever.</li> <li>Result TTL (Time to live): The time to live value (in seconds) of the job result.<ul> <li><code>-1</code>: Result never expires, you should delete jobs manually.</li> <li><code>0</code>: Result gets deleted immediately.</li> <li><code>n</code> (where <code>n &gt; 0</code>) : Result expires after n seconds.</li> </ul> </li> </ul> <p>Once you are done, click Save and your job will be persisted to django database.</p>"},{"location":"usage/#support-for-arguments-for-jobs","title":"Support for arguments for jobs","text":"<p>django-tasks-scheduler supports scheduling jobs calling methods with arguments, as well as arguments that should be calculated in runtime.</p> <p></p>"},{"location":"usage/#scheduled-task-run-once","title":"Scheduled Task: run once","text":"<p>No additional steps are required.</p>"},{"location":"usage/#repeatable-task-run-a-job-multiple-time-based-on-interval","title":"Repeatable Task: Run a job multiple time based on interval","text":"<p>These additional fields are required:</p> <ul> <li>Enter an Interval, and choose the Interval unit. This will calculate the time before the function is called   again.</li> <li>In the Repeat field, enter the number of time the job is to be run. Leaving the field empty, means the job will   be scheduled to run forever.</li> </ul>"},{"location":"usage/#cron-task-run-a-job-multiple-times-based-on-cron","title":"Cron Task: Run a job multiple times based on cron","text":"<p>These additional fields are required:</p> <ul> <li>In the Repeat field, enter the number of time the job is to be run. Leaving the field empty, means the job will be   scheduled to run forever.</li> <li>In the cron string field, enter a cron string describing how often the job should run.</li> </ul>"},{"location":"usage/#enqueue-jobs-using-the-command-line","title":"Enqueue jobs using the command line","text":"<p>It is possible to queue a job to be executed from the command line using django management command:</p> <pre><code>python manage.py run_job -q {queue} -t {timeout} -r {result_ttl} {callable} {args}\n</code></pre>"},{"location":"usage/#running-a-worker-to-process-queued-jobs-in-the-background","title":"Running a worker to process queued jobs in the background","text":"<p>Create a worker to execute queued jobs on specific queues using:</p> <pre><code>python manage.py rqworker [-h] [--pid PIDFILE] [--burst] [--name NAME] [--worker-ttl WORKER_TTL] [--max-jobs MAX_JOBS] [--fork-job-execution FORK_JOB_EXECUTION]\n                          [--job-class JOB_CLASS] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n                          [--skip-checks]\n                          [queues ...]\n</code></pre> <p>More information about the different parameters can be found in the commands documentation. </p>"},{"location":"usage/#running-multiple-workers-as-unixlinux-services-using-systemd","title":"Running multiple workers as unix/linux services using systemd","text":"<p>You can have multiple workers running as system services. To have multiple rqworkers, edit the <code>/etc/systemd/system/rqworker@.service</code> file, make sure it ends with <code>@.service</code>, the following is example:</p> <pre><code># /etc/systemd/system/rqworker@.service\n[Unit]\nDescription = rqworker daemon\nAfter = network.target\n\n[Service]\nWorkingDirectory = {{ path_to_your_project_folder } }\nExecStart = /home/ubuntu/.virtualenv/{ { your_virtualenv } }/bin/python \\\n            {{ path_to_your_project_folder } }/manage.py \\\n            rqworker high default low\n# Optional \n# {{user to run rqworker as}}\nUser = ubuntu\n# {{group to run rqworker as}}\nGroup = www-data\n# Redirect logs to syslog\nStandardOutput = syslog\nStandardError = syslog\nSyslogIdentifier = rqworker\nEnvironment = OBJC_DISABLE_INITIALIZE_FORK_SAFETY = YES\nEnvironment = LC_ALL = en_US.UTF-8\nEnvironment = LANG = en_US.UTF-8\n\n[Install]\nWantedBy = multi-user.target\n</code></pre> <p>After you are done editing the file, reload the settings and start the new workers:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start rqworker@{1..3} \n</code></pre> <p>You can target a specific worker using its number:</p> <pre><code>sudo systemctl stop rqworker@2\n</code></pre>"}]}